## 머신러닝 프로세스



1. 비즈니스 문제 정의
2. 데이터 가져오기
3. 데이터 구조 훑어보기
4. 데이터 떼어놓기
5. 데이터 이해하기
6. 인사이트를 통해 새로운 특성 만들기
7. 데이터 준비하기
8. 모델 선택과 학습
9. 모델 세부 튜닝
10. 최종 모델 평가



### 문제정의

* 비즈니스의 목적이 무엇인가.
  - 이 모델을 어떻게 사용해 이익을 얻을까
  - 목적에 따라
    - 문제를 어떻게 구성할지
    - 어떤 알고리즘을 선택할지
    - 모델 평가에 어떤 성능지표를 사용할지
    - 모델 튜닝을 위해 얼마나 노력을 투여할지를 결정
  - 현재 솔루션은 어떻게 되어있나? 전문가 집단에게 문의.





### 머신러닝 준비

* 파이썬 : 많은 유용한 라이브러리, 간단함.
* Jupyter Notebook : 파이썬 결과를 그때그때 확인하기 위함.
* Numpy : 다중차원의 행렬 연산, 통계함수 등을 지원 해주는 라이브러리
* Pandas : 테이블 같은 자료구조를 지원해주는 라이브러리
* Matplotlib : plot을 표현할 수 있도록 지원해주는 라이브러리
* Scikit Learn : classification, regression 과 이와 관련된 다양한 알고리즘을 제공해주는 머신러닝 라이브러리
* Tensorflow : 머신러닝 프레임워크, 딥러닝 모델을 지원해준다.
* Anaconda : 파이썬 가상환경 구성. 프로젝트마다 필요한 파이썬 모듈을 설치하거나 파이썬 모듈을 다른 버전으로 환경설정 하기 위함.





### 데이터 가져오기

* 사용할 라이브러리(모듈) 설정
* 변수 및 함수 설정
  * 프로젝트 경로, 데이터 정의
  * Plot 이미지 저장 함수 등
* 데이터 다운로드





### 데이터 구조 확인

* pandas를 통해 csv파일을 확인함.
* 데이터 간략 확인 
  * .head(), .info()
  *  변수명[컬럼명].value_counts()
  * .describe() : 숫자형 특성
  * plot의 .hist()를 통해 데이터 히스토그램 확인.



### 데이터 분리

* 테스트 셋의 패턴이 트레인 셋의 패턴을 보면 뇌가 과대적합이 되기 쉬움.(데이터 스누핑)
* 랜덤 샘플링 = 80:20으로 랜덤하게 트레인과 테스트 셋을 분류
* sklearn.model_del_selection import train_test_split
* 데이터가 충분하지 않다면 무작위가 아닌 계층적 샘플링 수행
* 도메인 전문가를 통해 예측하려는 대상에 영향을 끼치는 주요 특성 확인.
* 중요 특징 칼럼을 pd.cut 으로 카테고리화 하고 value_counts()로 갯수와 비율확인
* 카테고리 기반 계층 샘플링(sklearn.model_selection import StratifiedShuffleSplit)





### 데이터 이해하기

* 지리적 데이터 시각화(loc, lat을 x, y)
* Target or label과 다른 특성 사이의 상관 관계
  * corr_matrix = pd객체.corr() 
* 산점도 매트릭스로 상관관계 파악하기
  * pandas.plotting import scatter_matrix





### 인사이트를 통해 새로운 특성 만들기

* 특성들의 조합
  * 특성들의 데이터 값 사칙연산



### 데이터 준비하기

* label과 데이터를 분리해서 가져오기
  * drop()을 통해 라벨을 버린 데이터셋으로 훈련셋 구성
  * [라벨 칼럼].copy()를 통해 라벨만 가져오기.
* 빈데이터 확인
  *  isnull().any()를 통해 빈
* 빈 데이터 정제 방법
  * 해당 구역을 제거(dropna(subset=[“칼럼명”])
  * 해당 특성을 제거(drop(“칼럼명”))
  * 특정 값으로 채우기(0, 평균, 중간값, .fillna(값, inplace))
  * 사이킷런의 SimpleImputer 사용
* 텍스트와 범주형 데이터 다루기
  * 사이킷런의 OrdinalEncoder 사용(순서)
  * 사이킷런의 OneHotEncoder 사용(순서가 없다.)
* 새로운 특성을 자동으로 추가해주는 클래스 만들기.
  * BaseEstimator, TransformerMixin
* 수치형 파이프 라인
  * 사이킷런의 Pipeline 사용
  * 결측값 채우기 : SimpleImputer()
  * 새로운 속성 추가
  * 정규화 : 표준화 스케일링 StandardScaler()
* 전체 파이프라인
  * num 은 수치형 파이프라인에
  * cat은 OneHotEncoder()





### 모델 선택과 학습

* train data를 학습하기
  * LinearRegression 적용
  * mean_squared_error 확인
* 모델 변경하기-1
  * 예측결과가 낮으면(과소적합)은 적용한 특성이 충분한 정보를 제공하지 못했거나 모델이 충분히 강하지 않았다.
  * 해결법은 더 강력한 모델을 선택하거나 규제를 감소하는 것.
  * DecisionTreeRegressor 적용
* 교차 검증을 사용한 평가
  * K-겹 교차검증(cross_val_score) : k개의 서브셋으로 무작위로 분할 한 다음 해당 모델 훈련 평가
* 모델 변경하기-2
  * RandomForestRegressor() 적용
  * 교차 검증을 통해 훈련세트와 rmse 값을 비교하여 과대적합인지 확인





### 모델 세부 튜닝

* 그리드 탐색
  * n_estimators와 max_features를 지정하여 해당 조합으로 가장 적당한 파라미터를 찾기.
* 랜덤 서치
  * n_estimators와 max_features의 범위를 지정하여 최적의 조합 찾기.





### 최종 모델 평가

* 특성 중요도와 결과
  * 최종모델을 통해 특성들의 중요도를 확인 할 수 있음.
  * 최종모델로 테스트데이터를 예측하고 rmse를 구함





### 고려해봐야할 문제들

* 충분하지 않은 양의 훈련 데이터
  * 대부분 머신러닝 알고리즘은 잘 작동하기위해 데이터가 많아야함
  * 아주 간단한 문제라도 학습을 위해 많은 데이터가 필요하다. 복잡한 문제는 더욱 많은 데이터가 필요하다.
* 대표성 없는 데이터
  * 일반화가 잘 되려면 일반화하기를 원하는 새로운 사례를 훈련 데이터가 잘 대표해야함
  * 단순한 선형 모델 또는 대표성 없는 데이터는 문제를 해결하기 힘들다
  * 샘플링 잡음(sampling noise) 샘플이 작으면 우연에 의한 대표성없는 데이터가 생김.
  * 샘플링 편향(sampling bias) 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 갖지 못함.
* 낮은 품질의 데이터
  * 훈련 데이터가 에러, 이상치(outlier), 잡음이 가득하다면 머신러닝이 학습하기 어려움.
  * 따라서 데이터 과학자들은 경험에 의해 데이터 정제에 노력을 많이 함.
  * 일부 샘플이 이상치라는 것이 명확하다면 무시하거나 수동으로 수정
  * 특성이 빠져있다면 특성을 채우거나 특성을 넣은 모델과 제외한 모델을 둘 다 구성해보기
* 관련 없는 특성
  * 쓸데 없는 데이터가 들어가면, 나오는 것도 쓸모 없을 수 있음(가비지 인, 가비지 아웃)
  * 훈련 데이터에 관련 없는 특성이 적고 관련 있는 특성이 충분해야 학습이 가능함.
  * 특성 공학(Feature engineering):  훈련에 사용할 좋은 특성들을 찾는 것
    * 특성 선택(feature selection): 가지고 있는 특성중에서 유용한 특성을 선택하여 훈련
    * 특성 추출(feature extract): 특성을 결합하여 새로운 유용한 특성 만듬
    * 새로운 데이터를 수집해서 새로운 특성 구성
* 훈련 데이터 과대적합(Overfitting)
  * 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 것.
  * 해결 방법
    * 파라미터 수가 적은 모델 선택
    * 훈련 데이터를 더 수집
    * 훈련 데이터 잡음 줄이기
    * 규제 적용
  * 규제(regularization): 모델을 단순하게 하고 과대 적합의 위험을 감소 시키기 위해 모델에 제약을 가하는 것.
  * 학습하는 동안 적용할 규제의 양은 하이퍼파라미터(학습 알고리즘의 파라미터)가 결정
* 훈련 데이터 과소적합(Underfitting)
  * 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못함
  * 과소적합 해결 방법
    * 모델 파리미터가 더 많은 강력한 모델을 선택
    * 학습 알고리즘에 더 좋은 특성을 제공(특성 공학)
    * 모델의 제약을 줄임(규제 하이퍼파라미터를 감소)
